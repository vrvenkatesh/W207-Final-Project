{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-42-517de24254bf>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_eager_execution\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36menable_eager_execution\u001B[0;34m(config, device_policy, execution_mode)\u001B[0m\n\u001B[1;32m   5876\u001B[0m         \u001B[0mdevice_policy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice_policy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5877\u001B[0m         \u001B[0mexecution_mode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexecution_mode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5878\u001B[0;31m         server_def=None)\n\u001B[0m\u001B[1;32m   5879\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5880\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36menable_eager_execution_internal\u001B[0;34m(config, device_policy, execution_mode, server_def)\u001B[0m\n\u001B[1;32m   5934\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mgraph_mode_has_been_used\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5935\u001B[0m       raise ValueError(\n\u001B[0;32m-> 5936\u001B[0;31m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001B[0m\u001B[1;32m   5937\u001B[0m   \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdefault_execution_mode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEAGER_MODE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5938\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#silence TF\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('games-features-cleaned.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Reviews'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RegEx Preprocessor, Encoding and Encoding Map Functions from Cornelia's Week 10 Notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define function for token encoder\n",
    "def encode(text_tensor, label):\n",
    "    text = text_tensor.numpy()[0]\n",
    "    encoded_text = encode(text)\n",
    "    return encoded_text, label\n",
    "\n",
    "#  wrap the encode function to a TF Operator\n",
    "def encode_map_fn(text, label):\n",
    "    return tf.py_function(encode, inp=[text, label],\n",
    "                          Tout=(tf.int64, tf.int64))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['DetailedDescrip'] = df['DetailedDescrip'].apply(preprocessor)\n",
    "df['Reviews'] = df['Reviews'].apply(preprocessor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_r = df[df['Reviews'] != ' ']\n",
    "df_r['Reviews'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_r.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_r['Metacritic'].min()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_r['Metacritic'].max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create sentiment column\n",
    "df_r['Sentiment'] = np.where(df_r.Metacritic.isin(np.arange(38,66)), 'negative',\n",
    "                          np.where(df_r.Metacritic.isin(np.arange(67,94)), 'positive', 'unknown'))\n",
    "\n",
    "# rename sentiment to positive = 1, negative = 0\n",
    "df_r['Sentiment'] = np.where(df_r.Sentiment.eq('positive'), 1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_r[['Metacritic', 'Reviews', 'Sentiment']].head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_r['Sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Metacritic and Sentiment histogram after preprocessing\n",
    "cols = ['Metacritic', 'Sentiment']\n",
    "nrows, ncols = 1, 2\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(10,3))\n",
    "for idx, ax in enumerate(axs):\n",
    "    sns.histplot(\n",
    "    data=df_r,\n",
    "    stat=\"count\",\n",
    "    x = cols[idx],\n",
    "    ax=ax\n",
    "    )\n",
    "\n",
    "    # add labels and ticks\n",
    "    ax.set(xlabel=cols[idx])\n",
    "    sns.despine()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Addressing Data Imbalance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# randomly draw 223 examples from each class\n",
    "temp_positive = df_r[df_r.Sentiment.eq(1)].sample(\n",
    "    n=223,\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "temp_negative = df_r[df_r.Sentiment.eq(0)]\n",
    "\n",
    "df_balanced = pd.concat(\n",
    "    [temp_positive, temp_negative],\n",
    "    axis=0)\n",
    "\n",
    "# shuffle df_balanced\n",
    "df_balanced.sample(frac=1) # frac=1 retains all the data\n",
    "df_balanced.reset_index(drop=True, inplace=True) # reset index\n",
    "\n",
    "print('After preprocessing, our data contains', df_balanced.shape[0], 'reviews.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_balanced = df_balanced[['Reviews', 'Sentiment']]\n",
    "df_balanced.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define target\n",
    "target = df_balanced.pop('Sentiment') # .pop removes sentiment col from df\n",
    "\n",
    "# target and review combined tensors\n",
    "data_tf = tf.data.Dataset.from_tensor_slices(\n",
    "    (df_balanced[['Reviews']].values, target.values)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set random seed\n",
    "tf.random.set_random_seed(0)\n",
    "\n",
    "# define splits for training, validation, test\n",
    "splits=[0.6, 0.2, 0.2]\n",
    "\n",
    "# shuffle data\n",
    "data_tf = data_tf.shuffle(\n",
    "    df_balanced.shape[0], reshuffle_each_iteration=False)\n",
    "\n",
    "data_tf_test = data_tf.take(int(df_balanced.shape[0]*splits[2]))\n",
    "data_tf_train_valid = data_tf.skip(int(df_balanced.shape[0]*splits[2]))\n",
    "data_tf_train = data_tf_train_valid.take(int(df_balanced.shape[0]*splits[0]))\n",
    "data_tf_valid = data_tf_train_valid.skip(int(df_balanced.shape[0]*splits[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# try and except the TF tokenizer\n",
    "\n",
    "try:\n",
    "    tokenizer = tfds.features.text.Tokenizer()\n",
    "except AttributeError:\n",
    "    tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "\n",
    "# create an instance of the Counter class\n",
    "token_counts = Counter()\n",
    "\n",
    "for example in data_tf_train:\n",
    "    tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print('Size of training vocabulary:', len(token_counts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}